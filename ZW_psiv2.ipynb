{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZW_model import LSTM\n",
    "from ZW_utils import std_classes,dataloading\n",
    "from ZW_dataset import PSI_Dataset\n",
    "import numpy as np\n",
    "\n",
    "classes = std_classes\n",
    "data_split_ratio = 0.85\n",
    "batch_size = 100\n",
    "max_epochs = 30\n",
    "learning_rate = 0.1\n",
    "model = LSTM(hidden_size=12,out_features=1)\n",
    "augmentation = False\n",
    "uniqueness = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config import DATA_DIRECTORY\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# layouts = np.load(DATA_DIRECTORY/\"v22DF_m2_sorted_layouts.npy\", allow_pickle=True)\n",
    "# results = np.load(DATA_DIRECTORY/\"v22DF_m2_sorted_results.npy\", allow_pickle=True)\n",
    "layouts = np.load(\"GPT_NA/initial_10k.npy\", allow_pickle=True)\n",
    "results = np.load(\"GPT_NA/results_initial_10k.npy\", allow_pickle=True)\n",
    "l2 = []\n",
    "r2 = []\n",
    "cutoff = 143.957\n",
    "for i,r in enumerate(results):\n",
    "    if r > 0:\n",
    "        l2.append(layouts[i])\n",
    "        r2.append(r)\n",
    "layouts = np.asanyarray(l2)\n",
    "results = np.asanyarray(r2)\n",
    "from split_functions import uniqueness_check\n",
    "esigns,equipments = uniqueness_check(layouts)\n",
    "sorted_equipments = equipments.copy()\n",
    "sorted_equipments.sort()\n",
    "sorted_results = []\n",
    "for se in sorted_equipments:\n",
    "    index = equipments.index(se)\n",
    "    sorted_results.append(results[index])\n",
    "eq_array = np.zeros((len(sorted_equipments),22))\n",
    "for i,e in enumerate(sorted_equipments):\n",
    "    for j,u in enumerate(e):\n",
    "        eq_array[i,j] = u\n",
    "re_array = np.array(sorted_results)\n",
    "equipment_chunks = []\n",
    "results_chunks = []\n",
    "for equipment in sorted_equipments:\n",
    "    for i in range(len(equipment)):\n",
    "        candidate_chunk = equipment[:i+1]\n",
    "        if candidate_chunk not in equipment_chunks:\n",
    "            equipment_chunks.append(candidate_chunk)\n",
    "            #checking the same chunks in eq array\n",
    "            chunk_indices = np.where((eq_array[:,:i+1] == candidate_chunk).all(axis=1))[0]\n",
    "            chunk_results = np.mean(re_array[chunk_indices])\n",
    "            results_chunks.append(chunk_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 28418.318143443412\n",
      "Epoch 1 loss: 28413.81858330682\n",
      "Epoch 2 loss: 28411.660144284262\n",
      "Epoch 3 loss: 28411.753923678883\n",
      "Epoch 4 loss: 28411.79763553312\n",
      "Epoch 5 loss: 28411.8199966913\n",
      "Epoch 6 loss: 28411.829346855746\n",
      "Epoch 7 loss: 28411.835106254748\n",
      "Epoch 8 loss: 28411.837021124546\n",
      "Epoch 9 loss: 28411.836786089527\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding from equipment chunks\n",
    "lengths = [len(e) for e in equipment_chunks]\n",
    "max_length = max(lengths)\n",
    "one_hot_chunks = []\n",
    "for equipment in equipment_chunks:\n",
    "    one_hot = np.zeros((max_length,12))\n",
    "    for i,e in enumerate(equipment):\n",
    "        one_hot[i,e] = 1\n",
    "    one_hot_chunks.append(one_hot)\n",
    "one_hot_chunks = np.array(one_hot_chunks)\n",
    "results_chunks = np.array(results_chunks)\n",
    "one_hot_tensors = torch.tensor(one_hot_chunks).float()\n",
    "results_tensors = torch.tensor(results_chunks).float()\n",
    "batch_size = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "max_epochs = 10\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for n in range(0, len(one_hot_tensors), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_input = one_hot_tensors[n : n + batch_size]\n",
    "        batch_output = results_tensors[n : n + batch_size]\n",
    "        batch_lengths = lengths[n : n + batch_size]\n",
    "        packed_batch_input = nn.utils.rnn.pack_padded_sequence(\n",
    "            batch_input, batch_lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        y_pred = model(packed_batch_input)\n",
    "        loss = torch.nn.functional.mse_loss(y_pred, batch_output.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(one_hot_tensors) / batch_size\n",
    "    train_loss.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch} loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# y_pred = model(packed_x)\n",
    "# loss = loss_function(y_pred, y)\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "# epoch_loss += loss.item()\n",
    "# _, predicted = torch.max(y_pred.data, 1)\n",
    "# train_total += y.size(0)\n",
    "# train_correct += (predicted == y).sum().item()\n",
    "# epoch_loss = epoch_loss / len(train_loader)\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# val_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PSI_Dataset(e, results, classes,block_size,training_type=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# training_set, validation_set = torch.utils.data.random_split(data, [int(data_split_ratio*len(data)), len(data)-int(data_split_ratio*len(data))])\n",
    "# train_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for epoch in range(max_epochs):\n",
    "#     model.train()\n",
    "#     for i, (x, y) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         y_pred = model(x)\n",
    "#         y_pred = y_pred.view(y.size(0),block_size)\n",
    "#         y = y.to(torch.float32)\n",
    "#         loss = torch.nn.functional.mse_loss(y_pred, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         for i, (x, y) in enumerate(val_loader):\n",
    "#             y_pred = model(x)\n",
    "#             y_pred = y_pred.view(y.size(0),block_size)\n",
    "#             y = y.to(torch.float32)\n",
    "#             loss = torch.nn.functional.mse_loss(y_pred, y)\n",
    "#             val_loss += loss.item()\n",
    "#         val_loss /= len(val_loader)\n",
    "#     print(f\"Epoch {epoch} - Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[255.2910],\n",
       "         [213.3581]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [255.8791]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [211.1716]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [255.9067]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [255.8386]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [255.8868]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [210.0258]],\n",
       "\n",
       "        [[255.2910],\n",
       "         [248.1066]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.tensor([[0,1],[0,2],[0,3],[0,4],[0,5],[0,7],[0,9],[0,11]]))\n",
    "# model(torch.tensor([[0,5,1],[0,5,2],[0,5,3],[0,5,4],[0,5,5],[0,5,7],[0,5,9],[0,5,11]]))\n",
    "# model(torch.tensor([[0,5,4,1],[0,5,4,2],[0,5,4,3],[0,5,4,4],[0,5,4,5],[0,5,4,7],[0,5,4,9],[0,5,4,11]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
