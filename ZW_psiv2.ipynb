{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZW_utils import std_classes, dataloading\n",
    "from ZW_dataset import PSI_Dataset\n",
    "import numpy as np\n",
    "from config import DATA_DIRECTORY\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from split_functions import uniqueness_check\n",
    "\n",
    "\n",
    "classes = std_classes\n",
    "data_split_ratio = 0.85\n",
    "batch_size = 8\n",
    "max_epochs = 30\n",
    "learning_rate = 1e-3\n",
    "block_size = 22\n",
    "n_embd = 32  # 32\n",
    "n_head = 4  # 4\n",
    "n_layer = 2  # 2\n",
    "dropout = 0.1  # 0.1\n",
    "vocab_size = len(classes)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layouts (3121,)\n",
      "25 [0, 1, 2, 1, 2, 3, 5, 4, 1, 5, 4] 143.66786601745056\n"
     ]
    }
   ],
   "source": [
    "# layouts = np.load(DATA_DIRECTORY/\"v22DF_m2_sorted_layouts.npy\", allow_pickle=True)\n",
    "# results = np.load(DATA_DIRECTORY/\"v22DF_m2_sorted_results.npy\", allow_pickle=True)\n",
    "layouts = np.load(\"GPT_NA_psitest/M2_data_8_layouts.npy\", allow_pickle=True)\n",
    "results = np.load(\"GPT_NA_psitest/M2_data_8_results.npy\", allow_pickle=True)\n",
    "l2 = []\n",
    "r2 = []\n",
    "cutoff = 143.957\n",
    "for i, r in enumerate(results):\n",
    "    if r > 0 and r < cutoff:\n",
    "        l2.append(layouts[i])\n",
    "        r2.append(r)\n",
    "layouts = np.asanyarray(l2)\n",
    "results = np.asanyarray(r2)\n",
    "print(\"layouts\", layouts.shape)\n",
    "\n",
    "designs, equipments = uniqueness_check(layouts)\n",
    "sorted_equipments = equipments.copy()\n",
    "sorted_equipments.sort()\n",
    "sorted_results = []\n",
    "for se in sorted_equipments:\n",
    "    index = equipments.index(se)\n",
    "    sorted_results.append(results[index])\n",
    "eq_array = np.zeros((len(sorted_equipments), 22))\n",
    "for i, e in enumerate(sorted_equipments):\n",
    "    for j, u in enumerate(e):\n",
    "        eq_array[i, j] = u\n",
    "re_array = np.array(sorted_results)\n",
    "equipment_chunks = []\n",
    "results_chunks = []\n",
    "for equipment in sorted_equipments:\n",
    "    for i in range(len(equipment)):\n",
    "        candidate_chunk = equipment[: i + 1]\n",
    "        if candidate_chunk not in equipment_chunks:\n",
    "            equipment_chunks.append(candidate_chunk)\n",
    "            # checking the same chunks in eq array\n",
    "            chunk_indices = np.where(\n",
    "                (eq_array[:, : i + 1] == candidate_chunk).all(axis=1)\n",
    "            )[0]\n",
    "            chunk_results = np.min(re_array[chunk_indices])\n",
    "            results_chunks.append(chunk_results)\n",
    "print(25,equipment_chunks[25], results_chunks[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15773, 19]) torch.Size([15773, 1])\n"
     ]
    }
   ],
   "source": [
    "lengths = torch.tensor([x for x in map(len, equipment_chunks)])\n",
    "max_length = max(lengths)\n",
    "input_data = np.ones((len(equipment_chunks), max_length)) * 12\n",
    "for i, e in enumerate(equipment_chunks):\n",
    "    input_data[i, : len(e)] = e\n",
    "input_data = torch.tensor(input_data)\n",
    "target_data = torch.tensor(results_chunks).float().reshape(-1, 1)\n",
    "print(input_data.shape, target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the target data to be between 0 and 1\n",
    "# print(target_data.min().item(), target_data.max().item())\n",
    "target_data = (target_data - target_data.min()) / (target_data.max() - target_data.min())\n",
    "# standardizing the target data\n",
    "# target_data = (target_data - target_data.mean()) / target_data.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  7.,  5.,  4.,  1.,  7.,  1.,  5.,  2.,  3.,  9.,\n",
      "        11., 12., 12., 12., 12.], dtype=torch.float64) tensor([0.5131]) tensor(15)\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(len(input_data))\n",
    "input_data = input_data[indices]\n",
    "target_data = target_data[indices]\n",
    "lengths = lengths[indices]\n",
    "train_data = input_data[: int(0.85 * len(input_data))]\n",
    "train_target = target_data[: int(0.85 * len(input_data))]\n",
    "train_lengths = lengths[: int(0.85 * len(input_data))]\n",
    "val_data = input_data[int(0.85 * len(input_data)) :]\n",
    "val_target = target_data[int(0.85 * len(input_data)) :]\n",
    "val_lengths = lengths[int(0.85 * len(input_data)) :]\n",
    "print(train_data[25], train_target[25], train_lengths[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(21, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x != 12).float()\n",
    "        x = x * mask\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# LSTM model with masked input where the token is 12 (padding)\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(21, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x != 12).float()\n",
    "        x = x * mask\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTM_packed(nn.Module):\n",
    "    def __init__(self, embd_size,hidden_size):\n",
    "        super(LSTM_packed, self).__init__()\n",
    "        self.embedding = nn.Embedding(13, embd_size)\n",
    "        self.lstm = nn.LSTM(embd_size, hidden_size, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x.long())\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        output, (hidden, _) = self.lstm(x)\n",
    "        x = self.fc(hidden[-1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Prediction 128 1024\n",
      "batch_size 4 found epoch 27\n",
      "Mean Error: 5.25%\n",
      "Target: 0.50 Prediction: 0.51 Error: 1.80\n",
      "Target: 0.67 Prediction: 0.70 Error: 4.15\n",
      "Target: 0.84 Prediction: 0.85 Error: 1.12\n",
      "Target: 0.79 Prediction: 0.81 Error: 1.97\n",
      "Target: 0.57 Prediction: 0.60 Error: 4.59\n"
     ]
    }
   ],
   "source": [
    "for embd_size in [128]:\n",
    "    for hidden_size in [1024]:\n",
    "        batch_size = 4\n",
    "        patience = 10\n",
    "        model = LSTM_packed(embd_size,hidden_size)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        best_loss = 1e9\n",
    "        for epoch in range(max_epochs+1):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for i in range(0, len(train_data), batch_size):\n",
    "                input_batch = train_data[i : i + batch_size]\n",
    "                target_batch = train_target[i : i + batch_size]\n",
    "                lengths_batch = train_lengths[i : i + batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                output = model(input_batch, lengths_batch)\n",
    "                loss = criterion(output, target_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            epoch_loss /= len(train_data) / batch_size\n",
    "            \n",
    "            indices = torch.randperm(len(train_data))\n",
    "            train_data = train_data[indices]\n",
    "            train_target = train_target[indices]\n",
    "            train_lengths = train_lengths[indices]\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for i in range(0, len(val_data), batch_size):\n",
    "                    input_batch = val_data[i : i + batch_size]\n",
    "                    target_batch = val_target[i : i + batch_size]\n",
    "                    lengths_batch = val_lengths[i : i + batch_size]\n",
    "                    output = model(input_batch, lengths_batch)\n",
    "                    loss = criterion(output, target_batch)\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= len(val_data) / batch_size\n",
    "            if val_loss < best_loss:\n",
    "                best_model_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                patience = 10\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience == 0:\n",
    "                break\n",
    "            # print(f\"Epoch {epoch} Training Loss: {epoch_loss:.2f} Validation Loss: {val_loss:.2f}\")\n",
    "            #random prediction\n",
    "            random_index = np.random.randint(0, len(val_data))\n",
    "            random_input = val_data[random_index]\n",
    "            random_target = val_target[random_index]\n",
    "            random_length = val_lengths[random_index]\n",
    "            random_output = model(random_input.unsqueeze(0), random_length.unsqueeze(0))\n",
    "            # print(f\"Target: {random_target.item():.2f} Prediction: {random_output.item():.2f} Error: {abs(random_target.item() - random_output.item())/random_target.item()*100:.2f}\")\n",
    "        torch.save(best_model, f\"psi_norm_min_{embd_size}_{hidden_size}_{batch_size}_{cutoff}_8.pt\")\n",
    "        # best model prediction and mean error\n",
    "        model.load_state_dict(best_model)\n",
    "        model.eval()\n",
    "        print(\"Best Model Prediction\",embd_size,hidden_size)\n",
    "        print(\"batch_size\",batch_size,\"found epoch\",best_model_epoch)\n",
    "        mean_error = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(val_data)):\n",
    "                input_batch = val_data[i].unsqueeze(0)\n",
    "                target_batch = val_target[i].unsqueeze(0)\n",
    "                lengths_batch = val_lengths[i].unsqueeze(0)\n",
    "                output = model(input_batch, lengths_batch)\n",
    "                if target_batch.item() == 0:\n",
    "                    continue\n",
    "                mean_error += ((torch.abs(output - target_batch))/torch.abs(target_batch)).item()\n",
    "            mean_error /= len(val_data)\n",
    "            print(f\"Mean Error: {mean_error*100:.2f}%\")\n",
    "            for i in range(5):\n",
    "                random_index = np.random.randint(0, len(val_data))\n",
    "                random_input = val_data[random_index]\n",
    "                random_target = val_target[random_index]\n",
    "                random_length = val_lengths[random_index]\n",
    "                random_output = model(random_input.unsqueeze(0), random_length.unsqueeze(0))\n",
    "                print(f\"Target: {random_target.item():.2f} Prediction: {random_output.item():.2f} Error: {abs((random_target.item() - random_output.item())/random_target.item())*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best model prediction and mean error\n",
    "# embd_size = 128\n",
    "# hidden_size = 1024\n",
    "# batch_size = 100\n",
    "# cutoff = 143.957\n",
    "# model = LSTM_packed(embd_size,hidden_size)\n",
    "# model.load_state_dict(torch.load(f\"psi_norm_{embd_size}_{hidden_size}_100_1.pt\"))\n",
    "# model.eval()\n",
    "# print(\"Best Model Prediction\",embd_size,hidden_size)\n",
    "# # print(\"batch_size\",batch_size,\"found epoch\",best_model_epoch)\n",
    "# mean_error = 0\n",
    "# with torch.no_grad():\n",
    "#     for i in range(0, len(input_data)):\n",
    "#         input_batch = input_data\n",
    "#         target_batch = target_data\n",
    "#         lengths_batch = lengths\n",
    "#         output = model(input_batch, lengths_batch)\n",
    "#         if target_batch.item() == 0:\n",
    "#             continue\n",
    "#         mean_error += ((torch.abs(output - target_batch))/torch.abs(target_batch)).item()\n",
    "#     mean_error /= len(input_data)\n",
    "#     print(f\"Mean Error: {mean_error*100:.2f}%\")\n",
    "\n",
    "\n",
    "#     mean_val = np.mean(val_target.numpy())\n",
    "#     predicted = np.zeros(len(val_data))\n",
    "#     ssres = 0 \n",
    "#     for i in range(len(val_data)):\n",
    "#         # random_index = np.random.randint(0, len(val_data))\n",
    "#         random_index = i\n",
    "#         random_input = val_data[random_index]\n",
    "#         random_target = val_target[random_index]\n",
    "#         random_length = val_lengths[random_index]\n",
    "#         random_output = model(random_input.unsqueeze(0), random_length.unsqueeze(0))\n",
    "#         predicted[i] = random_output.item()\n",
    "#         ssres += (random_target - random_output)**2\n",
    "#         # print(f\"Target: {random_target.item():.2f} Prediction: {random_output.item():.2f} Error: {abs((random_target.item() - random_output.item())/random_target.item())*100:.2f}\")\n",
    "#     sstot = np.sum((val_target.numpy() - mean_val)**2)\n",
    "#     r2 = 1 - ssres/sstot\n",
    "#     print(\"R2\",r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
