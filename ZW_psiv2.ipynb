{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZW_utils import std_classes, dataloading\n",
    "from ZW_dataset import PSI_Dataset\n",
    "import numpy as np\n",
    "from config import DATA_DIRECTORY\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from split_functions import uniqueness_check\n",
    "\n",
    "\n",
    "classes = std_classes\n",
    "data_split_ratio = 0.85\n",
    "batch_size = 8\n",
    "max_epochs = 30\n",
    "learning_rate = 1e-3\n",
    "block_size = 22\n",
    "n_embd = 32  # 32\n",
    "n_head = 4  # 4\n",
    "n_layer = 2  # 2\n",
    "dropout = 0.1  # 0.1\n",
    "vocab_size = len(classes)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layouts (5672,)\n",
      "5672 before augmentation\n",
      "min\n",
      "Augmenting\n",
      "71728 71728\n",
      "25 [0, 3, 5, 4, 1, 5, 2] 141.32641306178036\n",
      "360202 360202\n"
     ]
    }
   ],
   "source": [
    "# layouts = np.load(DATA_DIRECTORY/\"v22DF_m2_sorted_layouts.npy\", allow_pickle=True)\n",
    "# results = np.load(DATA_DIRECTORY/\"v22DF_m2_sorted_results.npy\", allow_pickle=True)\n",
    "layouts = np.load(\"LSTM_NA_complimited/M2_data_F8_layouts.npy\", allow_pickle=True)\n",
    "results = np.load(\"LSTM_NA_complimited/M2_data_F8_results.npy\", allow_pickle=True)\n",
    "l2 = []\n",
    "r2 = []\n",
    "cutoff = 170\n",
    "aug = True\n",
    "for i, r in enumerate(results):\n",
    "    if r > 0 and r < cutoff:\n",
    "        l2.append(layouts[i])\n",
    "        r2.append(r)\n",
    "layouts = np.asanyarray(l2)\n",
    "results = np.asanyarray(r2)\n",
    "print(\"layouts\", layouts.shape)\n",
    "indices = np.argsort(results)\n",
    "layouts = layouts[indices]\n",
    "results = results[indices]\n",
    "layouts = layouts[:]\n",
    "results = results[:]\n",
    "designs, equipments = uniqueness_check(layouts)\n",
    "print(len(equipments),\"before augmentation\")\n",
    "print(\"min\")\n",
    "if aug == True:\n",
    "    print(\"Augmenting\")\n",
    "    data = equipments\n",
    "    results = results\n",
    "    augmented_results = []\n",
    "    augmented = []\n",
    "    for design in data:\n",
    "        base = np.array(design)\n",
    "        base_result = results[data.index(design)]\n",
    "        nognoe = base[1:-1]\n",
    "        for j in range(1, len(nognoe)):\n",
    "            new_rep = np.roll(nognoe, j, axis=0)\n",
    "            augmented.append(\n",
    "                np.concatenate((base[0:1], new_rep, base[-1:]), axis=0).tolist()\n",
    "            )\n",
    "            augmented_results.append(base_result)\n",
    "    equipments = equipments + augmented\n",
    "    results = np.concatenate((results, augmented_results), axis=0)\n",
    "sorted_equipments = np.array(equipments.copy(),dtype=object)\n",
    "index = np.argsort([len(e) for e in equipments])\n",
    "sorted_equipments = sorted_equipments[index].tolist()\n",
    "sorted_results = results[index]\n",
    "print(len(sorted_equipments), len(results))\n",
    "eq_array = np.zeros((len(sorted_equipments), 22))\n",
    "for i, e in enumerate(sorted_equipments):\n",
    "    for j, u in enumerate(e):\n",
    "        eq_array[i, j] = u\n",
    "re_array = np.array(sorted_results)\n",
    "equipment_chunks = []\n",
    "results_chunks = []\n",
    "for equipment in sorted_equipments:\n",
    "    for i in range(len(equipment)):\n",
    "        candidate_chunk = equipment[: i + 1]\n",
    "        if candidate_chunk not in equipment_chunks:\n",
    "            equipment_chunks.append(candidate_chunk)\n",
    "            # checking the same chunks in eq array\n",
    "            chunk_indices = np.where(\n",
    "                (eq_array[:, : i + 1] == candidate_chunk).all(axis=1)\n",
    "            )[0]\n",
    "            chunk_results = np.min(re_array[chunk_indices])\n",
    "            results_chunks.append(chunk_results)\n",
    "print(25,equipment_chunks[25], results_chunks[25])\n",
    "print(len(equipment_chunks), len(results_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([360202, 21]) torch.Size([360202, 1])\n"
     ]
    }
   ],
   "source": [
    "lengths = torch.tensor([x for x in map(len, equipment_chunks)])\n",
    "max_length = max(lengths)\n",
    "input_data = np.ones((len(equipment_chunks), max_length)) * 12\n",
    "for i, e in enumerate(equipment_chunks):\n",
    "    input_data[i, : len(e)] = e\n",
    "input_data = torch.tensor(input_data)\n",
    "target_data = torch.tensor(results_chunks).float().reshape(-1, 1)\n",
    "print(input_data.shape, target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.71270751953125 169.98951721191406\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# normalizing the target data to be between 0 and 1\n",
    "print(target_data.min().item(), target_data.max().item())\n",
    "target_data = (target_data - target_data.min()) / (target_data.max() - target_data.min())*1\n",
    "print(target_data.min().item(), target_data.max().item())\n",
    "# standardizing the target data\n",
    "# target_data = (target_data - target_data.mean()) / target_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  5.,  3.,  4.,  1.,  4.,  5.,  1., 12., 12., 12., 12., 12., 12.,\n",
      "        12., 12., 12., 12., 12., 12., 12.], dtype=torch.float64) tensor([0.4235]) tensor(8)\n"
     ]
    }
   ],
   "source": [
    "indices = torch.randperm(len(input_data))\n",
    "input_data = input_data[indices]\n",
    "target_data = target_data[indices]\n",
    "lengths = lengths[indices]\n",
    "train_data = input_data[: int(0.85 * len(input_data))]\n",
    "train_target = target_data[: int(0.85 * len(input_data))]\n",
    "train_lengths = lengths[: int(0.85 * len(input_data))]\n",
    "val_data = input_data[int(0.85 * len(input_data)) :]\n",
    "val_target = target_data[int(0.85 * len(input_data)) :]\n",
    "val_lengths = lengths[int(0.85 * len(input_data)) :]\n",
    "print(train_data[25], train_target[25], train_lengths[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(21, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x != 12).float()\n",
    "        x = x * mask\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# LSTM model with masked input where the token is 12 (padding)\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(21, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x != 12).float()\n",
    "        x = x * mask\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTM_packed(nn.Module):\n",
    "    def __init__(self, embd_size,hidden_size):\n",
    "        super(LSTM_packed, self).__init__()\n",
    "        self.embedding = nn.Embedding(13, embd_size)\n",
    "        self.lstm = nn.LSTM(embd_size, hidden_size, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x.long())\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        output, (hidden, _) = self.lstm(x)\n",
    "        x = self.fc(hidden[-1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "Epoch 0\n",
      "Epoch 5\n",
      "Epoch 10\n",
      "Epoch 15\n",
      "Epoch 20\n",
      "Epoch 25\n",
      "Best Model Prediction 64 256\n",
      "batch_size 4 found epoch 19\n",
      "Mean Error: 16.54%\n",
      "Target: 0.75 Prediction: 0.72 Error: 3.00\n",
      "Target: 0.33 Prediction: 0.36 Error: 7.89\n",
      "Target: 0.20 Prediction: 0.25 Error: 28.34\n",
      "Target: 0.77 Prediction: 0.78 Error: 1.80\n",
      "Target: 0.41 Prediction: 0.27 Error: 33.88\n"
     ]
    }
   ],
   "source": [
    "print(cutoff)\n",
    "for embd_size in [64]:\n",
    "    for hidden_size in [256]:\n",
    "        batch_size = 4\n",
    "        patience = 10\n",
    "        model = LSTM_packed(embd_size,hidden_size)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        best_loss = 1e9\n",
    "        for epoch in range(max_epochs+1):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"Epoch {epoch}\")\n",
    "            for i in range(0, len(train_data), batch_size):\n",
    "                input_batch = train_data[i : i + batch_size]\n",
    "                target_batch = train_target[i : i + batch_size]\n",
    "                lengths_batch = train_lengths[i : i + batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                output = model(input_batch, lengths_batch)\n",
    "                loss = criterion(output, target_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            epoch_loss /= len(train_data) / batch_size\n",
    "            \n",
    "            indices = torch.randperm(len(train_data))\n",
    "            train_data = train_data[indices]\n",
    "            train_target = train_target[indices]\n",
    "            train_lengths = train_lengths[indices]\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for i in range(0, len(val_data), batch_size):\n",
    "                    input_batch = val_data[i : i + batch_size]\n",
    "                    target_batch = val_target[i : i + batch_size]\n",
    "                    lengths_batch = val_lengths[i : i + batch_size]\n",
    "                    output = model(input_batch, lengths_batch)\n",
    "                    loss = criterion(output, target_batch)\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= len(val_data) / batch_size\n",
    "            if val_loss < best_loss:\n",
    "                best_model_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_model = model.state_dict()\n",
    "                patience = 10\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience == 0:\n",
    "                break\n",
    "            # print(f\"Epoch {epoch} Training Loss: {epoch_loss:.2f} Validation Loss: {val_loss:.2f}\")\n",
    "            #random prediction\n",
    "            random_index = np.random.randint(0, len(val_data))\n",
    "            random_input = val_data[random_index]\n",
    "            random_target = val_target[random_index]\n",
    "            random_length = val_lengths[random_index]\n",
    "            random_output = model(random_input.unsqueeze(0), random_length.unsqueeze(0))\n",
    "            # print(f\"Target: {random_target.item():.2f} Prediction: {random_output.item():.2f} Error: {abs(random_target.item() - random_output.item())/random_target.item()*100:.2f}\")\n",
    "        torch.save(best_model, f\"psi_norm_min_aug_complimited_{embd_size}_{hidden_size}_{batch_size}_{cutoff}_8.pt\")\n",
    "        # best model prediction and mean error\n",
    "        model.load_state_dict(best_model)\n",
    "        model.eval()\n",
    "        print(\"Best Model Prediction\",embd_size,hidden_size)\n",
    "        print(\"batch_size\",batch_size,\"found epoch\",best_model_epoch)\n",
    "        mean_error = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(val_data)):\n",
    "                input_batch = val_data[i].unsqueeze(0)\n",
    "                target_batch = val_target[i].unsqueeze(0)\n",
    "                lengths_batch = val_lengths[i].unsqueeze(0)\n",
    "                output = model(input_batch, lengths_batch)\n",
    "                if target_batch.item() == 0:\n",
    "                    continue\n",
    "                mean_error += ((torch.abs(output - target_batch))/torch.abs(target_batch)).item()\n",
    "            mean_error /= len(val_data)\n",
    "            print(f\"Mean Error: {mean_error*100:.2f}%\")\n",
    "            for i in range(5):\n",
    "                random_index = np.random.randint(0, len(val_data))\n",
    "                random_input = val_data[random_index]\n",
    "                random_target = val_target[random_index]\n",
    "                random_length = val_lengths[random_index]\n",
    "                random_output = model(random_input.unsqueeze(0), random_length.unsqueeze(0))\n",
    "                if random_target.item() == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Target: {random_target.item():.2f} Prediction: {random_output.item():.2f} Error: {abs((random_target.item() - random_output.item())/random_target.item())*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Prediction\n",
      "Min Target: 0.00 Prediction: 0.57\n",
      "Max Target: 100.00 Prediction: 43.50 Error: 56.50\n"
     ]
    }
   ],
   "source": [
    "#prediction for minimum and maximum data\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "print(\"Best Model Prediction\")\n",
    "min_index = np.argmin(target_data)\n",
    "max_index = np.argmax(target_data)\n",
    "min_input = input_data[min_index]\n",
    "min_target = target_data[min_index]\n",
    "min_length = lengths[min_index]\n",
    "max_input = input_data[max_index]\n",
    "max_target = target_data[max_index]\n",
    "max_length = lengths[max_index]\n",
    "min_output = model(min_input.unsqueeze(0), min_length.unsqueeze(0))\n",
    "max_output = model(max_input.unsqueeze(0), max_length.unsqueeze(0))\n",
    "print(f\"Min Target: {min_target.item():.2f} Prediction: {min_output.item():.2f}\")\n",
    "print(f\"Max Target: {max_target.item():.2f} Prediction: {max_output.item():.2f} Error: {abs((max_target.item() - max_output.item())/max_target.item())*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best model prediction and mean error\n",
    "# embd_size = 128\n",
    "# hidden_size = 128\n",
    "# batch_size = 4\n",
    "# cutoff = 144\n",
    "# model = LSTM_packed(embd_size,hidden_size)\n",
    "# model.load_state_dict(torch.load(f\"psi_norm_100max_{embd_size}_{hidden_size}_{batch_size}_{cutoff}_8.pt\"))\n",
    "# model.eval()\n",
    "# print(\"Best Model Prediction\",embd_size,hidden_size)\n",
    "# # print(\"batch_size\",batch_size,\"found epoch\",best_model_epoch)\n",
    "# mean_error = 0\n",
    "# with torch.no_grad():\n",
    "#     mean_val = np.mean(val_target.numpy())\n",
    "#     predicted = np.zeros(len(val_data))\n",
    "#     ssres = 0 \n",
    "#     for i in range(len(val_data)):\n",
    "#         # random_index = np.random.randint(0, len(val_data))\n",
    "#         random_index = i\n",
    "#         random_input = val_data[random_index]\n",
    "#         random_target = val_target[random_index]\n",
    "#         random_length = val_lengths[random_index]\n",
    "#         random_output = model(random_input.unsqueeze(0), random_length.unsqueeze(0))\n",
    "#         predicted[i] = random_output.item()\n",
    "#         ssres += (random_target - random_output)**2\n",
    "#         # print(f\"Target: {random_target.item():.2f} Prediction: {random_output.item():.2f} Error: {abs((random_target.item() - random_output.item())/random_target.item())*100:.2f}\")\n",
    "#     sstot = np.sum((val_target.numpy() - mean_val)**2)\n",
    "#     mse = ssres/len(val_data)\n",
    "#     print(\"MSE\",mse)\n",
    "#     r2 = 1 - ssres/sstot\n",
    "#     print(\"R2\",r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
