{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68026 68026\n",
      "67345 67345\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from ZW_utils import std_classes\n",
    "from ZW_model import GPT\n",
    "from ZW_Opt import *\n",
    "from split_functions import bound_creation, layout_to_string_single_1d,equipments_to_strings\n",
    "from thermo_validity import *\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "classes = std_classes\n",
    "layouts = np.load(\"M2_data_300_8_augmented_layouts.npy\", allow_pickle=True)\n",
    "results = np.load(\"M2_data_300_8_augmented_results.npy\", allow_pickle=True)\n",
    "print(len(layouts), len(results))\n",
    "layouts = equipments_to_strings(layouts, classes)\n",
    "results = 1 - (results - 125) / 175\n",
    "indices = np.argsort(results)\n",
    "sorted_results = np.array(results)[indices]\n",
    "sorted_layouts = np.array(layouts)[indices]\n",
    "unique, indices = np.unique(sorted_layouts, return_index=True)\n",
    "unique_results = sorted_results[indices]\n",
    "unique_layouts = sorted_layouts[indices]\n",
    "print(len(unique_layouts), len(unique_results))\n",
    "layouts = unique_layouts.tolist()\n",
    "results = unique_results\n",
    "new_layouts = []\n",
    "new_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(layout):\n",
    "    # 1. One hot encoding from integer\n",
    "    layout = layout.astype(int)\n",
    "    stringlist = [\n",
    "        layout_to_string_single_1d(layout),\n",
    "    ]\n",
    "    valid_string = validity(stringlist)\n",
    "    if len(valid_string) == 0:\n",
    "        return -1\n",
    "    if valid_string[0] in new_layouts:\n",
    "        return new_results[new_layouts.index(valid_string[0])]\n",
    "    if valid_string[0] in layouts:\n",
    "        return results[layouts.index(valid_string[0])]\n",
    "    ohe = np.zeros((len(layout), len(classes)))\n",
    "    for i, l in enumerate(layout):\n",
    "        ohe[i, l] = 1\n",
    "    equipment, bounds, x, splitter = bound_creation(ohe)\n",
    "    swarmsize_factor = 7\n",
    "    nv = len(bounds)\n",
    "    particle_size = swarmsize_factor * nv\n",
    "    if 5 in equipment:\n",
    "        particle_size += -1 * swarmsize_factor\n",
    "    if 9 in equipment:\n",
    "        particle_size += -2 * swarmsize_factor\n",
    "    iterations = 30\n",
    "    try:\n",
    "        a = PSO(objective_function, bounds, particle_size, iterations, nv, equipment)\n",
    "        if a.result < 300:\n",
    "            # standardization between 125 and 300 to 1 and 0\n",
    "            value = 1 - (a.result - 125) / 175\n",
    "            new_layouts.append(valid_string[0])\n",
    "            new_results.append(value)\n",
    "            print(value, valid_string[0])\n",
    "        else:\n",
    "            value = -0.25\n",
    "    except:\n",
    "        value = -0.5\n",
    "    return value\n",
    "\n",
    "\n",
    "class Flowsheet:\n",
    "    def __init__(self) -> None:\n",
    "        self.column_count = 23\n",
    "        self.action_size = 12\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Flowsheet\"\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        blank_state = np.ones(self.column_count) * -1\n",
    "        blank_state[0] = 0\n",
    "        return blank_state\n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        column = np.where(state == -1)[0][0]\n",
    "        state[column] = action\n",
    "        return state\n",
    "\n",
    "    def get_valid_moves(self, state):\n",
    "        return state.reshape(-1) == -1\n",
    "\n",
    "    def check_win(self, state, action):\n",
    "        if action == 11:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_value_and_terminated(self, state, action):\n",
    "        if self.check_win(state, action):\n",
    "            value = evaluation(self.get_encoded_state(state))\n",
    "            return value, True\n",
    "        if np.sum(self.get_valid_moves(state)) == 0:\n",
    "            return -1, True\n",
    "        return -1, False\n",
    "\n",
    "    def get_encoded_state(self, state):\n",
    "        try:\n",
    "            column = np.where(state == -1)[0][0]\n",
    "        except:\n",
    "            column = self.column_count\n",
    "        encoded_state = state[:column]\n",
    "        return encoded_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,game,args,state,parent=None,action_taken=None,prior = 0,visit_count=0):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action_taken = action_taken\n",
    "        self.prior = prior\n",
    "\n",
    "        self.children = []\n",
    "\n",
    "        self.visit_count = visit_count\n",
    "        self.value_sum = 0\n",
    "    \n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "        for child in self.children:\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_ucb = ucb\n",
    "                best_child = child\n",
    "        return best_child\n",
    "    \n",
    "    def get_ucb(self,child):\n",
    "        if child.visit_count == 0:\n",
    "            q_value = 0\n",
    "        else:\n",
    "            q_value = ((child.value_sum / child.visit_count)+1)/2\n",
    "        return q_value + self.args[\"C\"] * (np.sqrt(self.visit_count) / (child.visit_count+1))*child.prior\n",
    "    def expand(self,policy):\n",
    "        for action, prob in enumerate(policy):\n",
    "            if prob > 0:\n",
    "                child_state = self.state.copy()\n",
    "                child_state = self.game.get_next_state(child_state,action)\n",
    "                child = Node(self.game,self.args,child_state,self,action,prob)\n",
    "                self.children.append(child)\n",
    "\n",
    "    def backpropagate(self,value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        if self.parent != None:\n",
    "            self.parent.backpropagate(value)\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self,game,args,model):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "        self.valid_moves = np.ones(self.game.action_size)\n",
    "        self.valid_moves[0],self.valid_moves[6],self.valid_moves[8],self.valid_moves[10] = 0,0,0,0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self,state):\n",
    "        root = Node(self.game,self.args,state,visit_count=1)\n",
    "        input = torch.tensor(self.game.get_encoded_state(state),dtype=torch.long).unsqueeze(0)\n",
    "        lengths = torch.tensor([x for x in map(len, input)])\n",
    "        policy,_ = self.model(\n",
    "            input,lengths\n",
    "        )\n",
    "        policy = torch.softmax(policy,axis=-1).squeeze(0).detach().numpy()\n",
    "        \n",
    "        policy = (1-self.args[\"dirichlet_epsilon\"])*policy + self.args[\"dirichlet_epsilon\"]\\\n",
    "            *np.random.dirichlet([self.args[\"dirichlet_alpha\"]]*self.game.action_size)\n",
    "\n",
    "        policy*=self.valid_moves\n",
    "        policy /= np.sum(policy)\n",
    "        root.expand(policy)\n",
    "        for search in range(self.args[\"num_searches\"]):\n",
    "            node = root\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "            value,is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
    "\n",
    "            if not is_terminal:\n",
    "                input = torch.tensor(self.game.get_encoded_state(node.state),dtype=torch.long).unsqueeze(0)\n",
    "                lengths = torch.tensor([x for x in map(len, input)])\n",
    "                policy,value = self.model(\n",
    "                    input,lengths\n",
    "                )\n",
    "                policy = torch.softmax(policy,axis=-1).squeeze(0).detach().numpy()\n",
    "                policy*=self.valid_moves\n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                value = value.item()\n",
    "                node.expand(policy)\n",
    "            node.backpropagate(value)\n",
    "        \n",
    "        action_probs = np.zeros(self.game.action_size)\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "        action_probs /= np.sum(action_probs)\n",
    "        return action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alphazero:\n",
    "    def __init__(self,model,optimizer,game,args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(game,args,model)\n",
    "\n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        state = self.game.get_initial_state()\n",
    "\n",
    "        while True:\n",
    "            action_probs = self.mcts.search(state)\n",
    "            memory.append((state,action_probs))\n",
    "            #Temperature lim 0 exploiation, lim inf exploration (more randomness)\n",
    "            temperature_action_probs = action_probs**(1/self.args[\"temperature\"])\n",
    "            temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "\n",
    "            action = np.random.choice(self.game.action_size,p=temperature_action_probs)\n",
    "            state = self.game.get_next_state(state,action)\n",
    "            value,is_terminal = self.game.get_value_and_terminated(state,action)\n",
    "            if is_terminal:\n",
    "                returnMemory = []\n",
    "                for hist_neutral_state,hist_action_probs in memory:\n",
    "                    hist_outcome = value \n",
    "                    returnMemory.append((\n",
    "                        self.game.get_encoded_state(hist_neutral_state),\n",
    "                        hist_action_probs,\n",
    "                        hist_outcome\n",
    "                    ))\n",
    "                return returnMemory\n",
    "\n",
    "\n",
    "    def train(self,memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0,len(memory),self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory)-1,batchIdx+self.args['batch_size'])]\n",
    "            states,policy_targets,value_targets = zip(*sample)\n",
    "            #padding necessicity\n",
    "            lengths = torch.tensor([len(x) for x in states])\n",
    "            max_length = max(lengths)\n",
    "            #padding to the maximum length\n",
    "            states = [x.tolist()+[12]*(max_length-len(x)) for x in states]\n",
    "            states,policy_targets,value_targets = np.array(states),np.array(policy_targets),np.array(value_targets).reshape(-1,1)            \n",
    "            states = torch.tensor(states).long()\n",
    "            policy_targets = torch.tensor(policy_targets).float()\n",
    "            value_targets = torch.tensor(value_targets).float()\n",
    "            \n",
    "            out_policy, out_value = self.model(states,lengths)\n",
    "\n",
    "            policy_loss = F.cross_entropy(out_policy,policy_targets)\n",
    "            value_loss = F.mse_loss(out_value,value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "\n",
    "    def learn(self):\n",
    "        for iteration in range(self.args[\"num_iterations\"]):\n",
    "            memory = []\n",
    "\n",
    "            for selfPlay_iteration in trange(self.args[\"num_selfPlay_iterations\"]):\n",
    "                memory += self.selfPlay()\n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args[\"num_epochs\"]):\n",
    "                self.train(memory)\n",
    "            save_path = self.args[\"save_path\"]\n",
    "            torch.save(self.model.state_dict(),f\"{save_path}/model_{iteration}_{self.game}.pt\")\n",
    "            torch.save(self.optimizer.state_dict(),f\"{save_path}/optimizer_{iteration}_{self.game}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_packed(nn.Module):\n",
    "    def __init__(self, embd_size,hidden_size):\n",
    "        super(LSTM_packed, self).__init__()\n",
    "        self.embedding = nn.Embedding(13, embd_size)\n",
    "        self.lstm = nn.LSTM(embd_size, hidden_size, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.valuehead = nn.Linear(hidden_size, 1)\n",
    "        self.policyhead = nn.Linear(hidden_size, 12)\n",
    "    def forward(self, x, lengths):\n",
    "        x = self.embedding(x.long())\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        output, (hidden, _) = self.lstm(x)\n",
    "        value = self.valuehead(hidden[-1])\n",
    "        policy = self.policyhead(hidden[-1])\n",
    "        return policy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4. 11. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1.]\n",
      "[ 0.  1.  2.  3.  4. 11.]\n",
      "-0.02481631562113762\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ttt = Flowsheet()\n",
    "state = ttt.get_initial_state()\n",
    "state = ttt.get_next_state(state,1)\n",
    "state = ttt.get_next_state(state,2)\n",
    "state = ttt.get_next_state(state,3)\n",
    "state = ttt.get_next_state(state,4)\n",
    "state = ttt.get_next_state(state,11)\n",
    "print(state)\n",
    "\n",
    "encoded_state = ttt.get_encoded_state(state)\n",
    "print(encoded_state)\n",
    "tensor_state = torch.tensor(encoded_state).unsqueeze(0)\n",
    "lengths = torch.tensor([x for x in map(len, tensor_state)])\n",
    "#untrained model\n",
    "model = LSTM_packed(64,256)\n",
    "# #trained model\n",
    "# model.load_state_dict(torch.load('model_2.pt'))\n",
    "model.eval()\n",
    "policy, value = model(tensor_state,lengths)\n",
    "value = value.item()\n",
    "policy = torch.softmax(policy,axis=1).squeeze(0).detach().numpy()\n",
    "print(value)\n",
    "plt.bar(range(ttt.action_size),policy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59152ee76fd24734bc5a27686da6da95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806575038489644 GCHTAE\n",
      "0.7053551270926197 GACHTE\n",
      "0.7111585440164447 GACACAHTE\n",
      "0.6676225580573714 GACACAHTACE\n",
      "0.7890828084358902 GTCACHE\n",
      "0.7408445226091437 GTHCTACE\n",
      "0.645114510521313 GTHCTACAE\n",
      "0.7185150863115103 GTaHTCa1A1C-1HCAE\n",
      "0.3632627909209486 GTaHTCa1A1C-1HCTAE\n",
      "0.8065773019702467 GHTACE\n",
      "0.7610518182038397 GHTATCE\n",
      "0.8065693457363965 GTACHE\n",
      "0.5122180206386161 GCHaHACTaTE\n",
      "0.6802753339067916 GTCACACHE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd8039ae4d04e3e978a743742f76084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902cfdc2ffe0450b92e3ea4a80fe4641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5235320746272839 GHATCHTE\n",
      "0.7466672951469439 GHATCHTHTE\n",
      "0.7073676400409311 GTACATACHE\n",
      "0.7068849322058839 GTACATCAHE\n",
      "0.6989699180904734 GTACATACAHE\n",
      "0.6504910912851065 GTACATACATHE\n",
      "0.742041732217191 GTACATACACHE\n",
      "0.6456069999651457 GTACATACAHCE\n",
      "0.8063221114988179 GHTACTE\n",
      "0.7694562955223944 GCaTHaTAE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e0e9629394295bad25474c067c03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0630d00ec4d444ebc4b92ee96bb69ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169106823068309 GAHTACE\n",
      "0.7264549665411203 GTAHTACE\n",
      "0.6087662257652953 GTATHTCACE\n",
      "0.7398547418863413 GHTCACE\n",
      "0.7070406461173626 GHTATCTAE\n",
      "0.8128094890337793 GHTACTHCE\n",
      "0.26106965113913505 GHTATCHAE\n",
      "0.7258384943607985 GHTATCAE\n",
      "0.7851207315229317 GHTATCHCE\n",
      "0.6525596981862098 GHTATCTCE\n",
      "0.8026500039280825 GHTATCTE\n",
      "0.7880987551649414 GHTATCACE\n",
      "0.684692734836238 GTCHTAE\n",
      "0.806573411464015 GTACTHE\n",
      "0.7637300844144899 GTACTHCE\n",
      "0.8042288516364375 GTACHCE\n",
      "0.7297521836994838 GTACAHE\n",
      "0.8065612152503772 GTHTACE\n",
      "0.7922702912711163 GTATATCHE\n",
      "0.7364335414177976 GTATATCHCE\n",
      "0.7210284514318568 GHTACHCE\n",
      "0.8260691621880608 GHTACHTCE\n",
      "0.826337439250223 GHTACHTE\n",
      "0.2665028278724929 GHTACHAE\n",
      "0.5001068870667492 GHTACHACE\n",
      "0.8262956760330593 GTACHTHE\n",
      "0.739447524739014 GTACHTAE\n",
      "0.6996761877592033 GTACAHCE\n",
      "0.8036837410194343 GTATCHE\n",
      "0.7969622247931943 GTATCHTCE\n",
      "0.2665031815851585 GTACHAHE\n",
      "0.5440568000341851 GTACHACHE\n",
      "0.7483724742482196 GH1TA1ACH-1E\n",
      "0.734111007708071 GH1TA1ACH-1AE\n",
      "0.7831465264416956 GHTATCACTE\n",
      "0.7077329570679605 GHTATCACTAE\n",
      "0.720648874755465 GTATCHTAE\n",
      "0.266491311570899 GTACTHAHE\n",
      "0.24343873146472916 GTACTHAHCE\n",
      "0.7593560766425209 GTATACHE\n",
      "0.7604213630662049 GTATACHCE\n",
      "0.7595682544101983 GTATCTHE\n",
      "0.6879305367862482 GTATCTHCE\n",
      "0.6522082749704896 GTCTACHCE\n",
      "0.46489034021301623 GHTCTCHACE\n",
      "0.3035782701015711 GHTCTCHACAE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02310d0f5ae471e95f20597e3f9c00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed2f51eda1b4c669f69c23d768d7e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7292706536238538 GTACTAHE\n",
      "0.8229620815498111 GATCHCHTE\n",
      "0.6000749348991381 GHTACAE\n",
      "0.6938936526500059 GHTACATE\n",
      "0.7627190968962699 GHTACACE\n",
      "0.43775030925082237 GaTCAHaACE\n",
      "0.7045913613443486 GTAHTACAE\n",
      "0.5959228871806974 GCHTCAE\n",
      "0.7233531475280799 GTCAHTAE\n",
      "0.8022359638273256 GTHCTATCE\n",
      "0.6822649145696271 GTHCTATCAE\n",
      "0.7308133975276832 GTHCTATCAHE\n",
      "0.7693035516513328 GTCATCHTAE\n",
      "0.7742218808460918 GTCATCHTCE\n",
      "0.5770872822424951 GAHTCTACE\n",
      "0.7057473761582294 GAHTCACE\n",
      "0.7258288612779051 GATCAHTE\n",
      "0.7143815258692642 GTHTACAE\n",
      "0.728582303413557 GHTACATHCE\n",
      "0.7410286230958847 GHTACATHTE\n",
      "0.6725888119724319 GTCATCTHE\n",
      "0.8063487987890884 GCTACHE\n",
      "0.6990525515673637 GCTACAHE\n",
      "0.7275326930038435 GTCTATCHE\n",
      "0.5317245575527529 GTCACHCE\n",
      "0.576954356439261 GTCACHCHE\n",
      "0.7002219378661847 GTCATHCTAE\n",
      "0.6648269889883693 GHCTACE\n",
      "0.2043404806832687 GTCAHTHAE\n",
      "0.39653454422335266 GTCAHTHACE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94871bd5bc1643ffa7e6fc41705a1e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6974594cdd4976a046a9eb38159177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6381804232191267 GCTATACHE\n",
      "0.7282073514483167 GCTATACHTE\n",
      "0.6665680526212119 GTACTATHE\n",
      "0.708094774974611 GTACTATAHE\n",
      "0.6037243202837289 GTACTATACHCE\n",
      "0.7197459826602626 GTACTATACHE\n",
      "0.6996641623531012 GTACTAHCE\n",
      "0.5555917168078742 GTACTAHCHE\n",
      "0.7658154415648348 GTACTCHE\n",
      "0.6416576957894259 GTACTCHCE\n",
      "0.6825359430763076 GTACTCHCHE\n",
      "0.2098297588567425 GHATAHTACE\n",
      "0.2664451566673095 GTAHTACHE\n",
      "0.32531680671121566 GTACTHACHE\n",
      "0.7217551398837194 GTACTCTHE\n",
      "0.7331754138564283 GTACTCTHCE\n",
      "0.7872309807264551 GTACTCTHCHE\n",
      "0.6887157160847307 GCTATACAHE\n",
      "0.7046509542781241 GCTACTHE\n",
      "0.7003264282610813 GCTACTCHE\n",
      "0.7051144642066107 GCHTATE\n",
      "0.7515901504321523 GCHTATAE\n",
      "0.7136996525133793 GTATACTHE\n",
      "0.6159263174972357 GTATACTAHE\n",
      "0.0213599060872256 GTATACTACHCE\n",
      "0.6542236130933266 GTATACTAHCE\n",
      "0.7169106871484359 GCAHTAE\n",
      "0.7115157897007702 GCAHTACAE\n",
      "0.489340777685876 GCTHACHE\n",
      "0.6930287272267563 GCTAHTAE\n",
      "0.8252365692187995 GTACTHCHE\n",
      "0.6003237515745288 GTACTHCHCE\n",
      "0.41614344977345497 GTACTHCHACHE\n",
      "0.7084110099117444 GAHTATCE\n",
      "0.7079966408682836 GAHTATCACE\n",
      "0.21487528916809584 GAHTACHE\n",
      "0.7285118968910529 GAHTACTE\n",
      "0.53295601799704 GAHTACTCE\n",
      "0.26648382020387695 GAHTACTHE\n",
      "0.14086660063487766 GAHTACTHCE\n",
      "0.2663440146375027 GAHTACTHTE\n",
      "0.672833280639896 GAHTATACE\n",
      "0.6969522884398736 GTACTACHCE\n",
      "0.7532526090781736 GTACTACHE\n",
      "0.6351557246266254 GTACTACAHCE\n",
      "0.6572745311850734 GTACTACAHE\n",
      "0.7746642812036874 GCHTACAE\n",
      "0.7873981796360957 GCHTACTE\n",
      "0.42701480205334696 GTACTACHCHCE\n",
      "0.67463080367451 GTATACAHE\n",
      "0.6080108103970568 GTATACAHCE\n",
      "0.6630545659579472 GTACAHTAE\n",
      "0.7367773181593319 GCTATCTHE\n",
      "0.7163829689863727 GACAHTE\n",
      "0.657055881156893 GATAHTACE\n",
      "0.667222759974194 GATAHTACTE\n",
      "0.6763024784690748 GATAHTACTCE\n",
      "0.2645194477751297 GTAHTACHCE\n",
      "0.03101399205316313 GTAHTACHCHE\n",
      "0.7133530387157652 GTCTAHTAE\n",
      "0.5338342079844793 GTCTAHTCACE\n",
      "0.5558749360776686 GTCTAHTCAE\n",
      "0.4754016337028185 GTCTAHTCACAE\n",
      "0.5057100475390273 GTCTAHTCACTCE\n",
      "0.7320363348765455 GCTATATCHE\n",
      "0.26476274043772585 GHTAHTACE\n",
      "0.4884689045116095 GHCTATACE\n",
      "0.741536692990576 GTCTATACHE\n",
      "0.5252159011836579 GHTHACE\n",
      "0.6781142449498991 GHCTATACAE\n",
      "0.6092398242174092 GHCTATACHTE\n",
      "0.7387903996511866 GHCTATACHCE\n",
      "0.48503628736180404 GTACTATHCE\n",
      "0.15676810854731882 GCTATHaCACaE\n",
      "0.8070247272945432 GTACHCHE\n",
      "0.7862309963660657 GTACHCHCE\n",
      "0.7133554359585037 GTATCTAHE\n",
      "0.5264380856023185 GCHTHAE\n",
      "0.6413708549757273 GATACTHTE\n",
      "0.6233506292996787 GTACTATCHCE\n",
      "0.7060521690122943 GTACTATCHE\n",
      "0.7169097342990742 GHTACTAE\n",
      "0.7876456613161429 GHTACTCE\n",
      "0.7887549793224949 GHTACTACE\n",
      "0.716677492890698 GHTACTATE\n",
      "0.7339263467104068 GHTACTATCE\n",
      "0.6307974669404356 GATACACHTE\n",
      "0.33898386787704304 GTHATCTAHE\n",
      "0.43403885894738814 GTHATCTATCHE\n",
      "0.3927397739263123 GTHATCTATCAHE\n",
      "0.17610727413390126 GTHATCTATCAHCE\n",
      "0.6851536057571659 GTACTHCTCE\n",
      "0.7815979495450617 GATACHTE\n",
      "0.5787364378011903 GATACHTCHE\n",
      "0.7002046658448662 GTACATHE\n",
      "0.6016795662383273 GTACATAHE\n",
      "0.7574146948112793 GHTATACE\n",
      "0.6744295138326135 GHTATACAE\n",
      "0.670129552957197 GHTATACTE\n",
      "0.6901403692023436 GHTATACTCE\n",
      "0.6709867648308071 GHTATACTAE\n",
      "0.6734201092884186 GHTATACTCAE\n",
      "0.694603919273 GHTATACTCACE\n",
      "0.6438290100308413 GHTATACTCATE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20b4cb51fcb478b83e9f21703039b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844874b40d854778b772387882c885fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8035801339677963 GATCHTE\n",
      "0.7310771735453752 GATCHTATE\n",
      "0.5350170732964913 GAHTCATCE\n",
      "0.5245918783687856 GAHTCATCTE\n",
      "0.11930044872350531 GAHTCATCHE\n",
      "0.42656645035866825 GHATCATAHTE\n",
      "0.6974870144559153 GHATCATAHTHTE\n",
      "0.445592563122181 GCHTHCAE\n",
      "0.40968766644620214 GCHTHCATE\n",
      "0.26046286003349106 GTHCHTHACE\n",
      "0.5983796248767608 GTCHTCACAE\n",
      "0.6706383767554088 GTHACHE\n",
      "0.2662487892207934 GHTACHATE\n",
      "0.1645014895031438 GTACTHACTHE\n",
      "0.3829646192861237 GTACTHACTHTCE\n",
      "0.28910244206585045 GHTCATCTE\n",
      "0.6469453522815074 GHTCATCTAE\n",
      "0.7690378796964858 GHTCATCTHTE\n",
      "0.7606348403313092 GTCHTATCE\n",
      "0.7416189969334833 GTCHTATAE\n",
      "0.2621405516708881 GHCAHTACE\n",
      "0.26650323333887416 GCHAHTAE\n",
      "0.5027619838332977 GCHCaAaTAE\n",
      "0.6487657120136487 GHTCACAE\n",
      "0.5939934881540037 GHTCACATE\n",
      "0.6996761726211931 GAHCTACE\n",
      "0.6960928892992201 GAHCTATCE\n",
      "0.8028077291583869 GCTHTAE\n",
      "0.5345327870967045 GHATCHCTE\n",
      "0.6183238038635586 GaHTATCACaHE\n",
      "0.296097380468173 GTHCHACHE\n",
      "0.4017523366919421 GTHCHACAHE\n",
      "0.6858646778601474 GCHTaHCaAE\n",
      "0.5167534615056638 GCHTaHCaTAE\n",
      "0.3937752847793835 GCHTaHCaTHAE\n",
      "0.248087181349964 GTCATHTHAE\n",
      "0.23910755346715118 GTCATHTHATCE\n",
      "0.7041084083428677 GCTACAHTE\n",
      "0.13320266084318977 GHTCATATCE\n",
      "0.40162630066952976 GAHTACHTE\n",
      "0.009637532157282469 GAHTACHCE\n",
      "0.21454040641655248 GAHTACHCTE\n",
      "0.49366906661910415 GTCHACHE\n",
      "0.3659108801201707 GTCHACAHE\n",
      "0.26380957322929377 GTCHACATHE\n",
      "0.6749175314658675 GHTACATAE\n",
      "0.6384361298584758 GHTACATATE\n",
      "0.7389606858403757 GHTACATACE\n",
      "0.7065551126814136 GHTACATACAE\n",
      "0.43346680553378614 GHTCHATCE\n",
      "0.8907750484944447 GHTaTCAaE\n",
      "0.6112452598985199 GTCHTHAE\n",
      "0.3572759220194779 GTCHTHCAE\n",
      "0.15895241411915229 GAHTAHACE\n",
      "0.3621998839211986 GTCAHATCTHE\n",
      "0.9314174736347816 GHTCTaATCaE\n",
      "0.6172090108832976 GTCATCAHE\n",
      "0.6109067875476412 GACHTHE\n",
      "0.82634916540355 GACHTHTE\n",
      "0.4518281010047849 GCHACHTE\n",
      "0.07934352489300345 GHAHTACE\n",
      "0.21401835086996535 GHAHTACTE\n",
      "0.3381182819887031 GHTHACAE\n",
      "0.6649170878298472 GHTHACAHTE\n",
      "0.7046871109781172 GHTHACAHTCE\n",
      "0.5870146874648563 GHTCATATCAE\n",
      "0.7133560901463478 GATCTAHTE\n",
      "0.3988715219378822 GAHTHCACE\n",
      "0.5246792945536176 GHTATHACE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b1c7411244a33a1b5f011cbbe839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game = Flowsheet()\n",
    "model = LSTM_packed(64,256)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001,weight_decay=1e-4)\n",
    "args = {\n",
    "    \"C\":2,\n",
    "    \"num_searches\":100,\n",
    "    \"num_iterations\":6,\n",
    "    \"num_selfPlay_iterations\":500,\n",
    "    \"num_epochs\":30,\n",
    "    \"batch_size\":100,\n",
    "    \"temperature\":1,\n",
    "    \"dirichlet_epsilon\":0.1,\n",
    "    \"dirichlet_alpha\":0.3,\n",
    "    \"save_path\":\"./RL/policy_value_model_trials\"\n",
    "}\n",
    "alphazero = Alphazero(model,optimizer,game,args)\n",
    "alphazero.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 [0. 1. 4. 5. 7. 1. 7. 4. 5. 1. 9. 9. 5. 5. 5. 2. 5. 9. 7. 2. 1. 1. 9.]\n"
     ]
    }
   ],
   "source": [
    "game = Flowsheet()\n",
    "args = {\n",
    "    \"C\":2,\n",
    "    \"num_searches\":100,\n",
    "    \"num_iterations\":6,\n",
    "    \"num_selfPlay_iterations\":500,\n",
    "    \"num_epochs\":30,\n",
    "    \"batch_size\":100,\n",
    "    \"temperature\":1,\n",
    "    \"dirichlet_epsilon\":0.1,\n",
    "    \"dirichlet_alpha\":0.3,\n",
    "    \"save_path\":\"./RL/policy_value_model_trials\"\n",
    "}\n",
    "model = LSTM_packed(64,256)\n",
    "model.state_dict(torch.load('RL/policy_value_model_trials/model_5_Flowsheet.pt'))\n",
    "model.eval()\n",
    "mcts = MCTS(game, args,model)\n",
    "state = game.get_initial_state()\n",
    "while True:\n",
    "    mcts_probs = mcts.search(state)\n",
    "    action = np.argmax(mcts_probs)\n",
    "        \n",
    "    state = game.get_next_state(state, action)\n",
    "    value,is_terminal = game.get_value_and_terminated(state,action)\n",
    "\n",
    "    if is_terminal:\n",
    "        print(value, state)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
