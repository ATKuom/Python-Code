{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from config import DATA_DIRECTORY\n",
    "import numpy as np\n",
    "from ZW_utils import std_classes\n",
    "from split_functions import layout_to_string\n",
    "\n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, data, classes, training_type=\"standard\"):\n",
    "        self.data = data\n",
    "        # Perform one-hot encoding for the sequences\n",
    "        self.data = self.one_hot_encoding(self.data, classes)\n",
    "        if training_type == \"augmented\":\n",
    "            self.data = self.augment_data(self.data)\n",
    "            self.adata = self.data\n",
    "        # input output preparation\n",
    "        self.data, self.labels, self.lengths = self.input_output_prep(self.data)\n",
    "        # Padding\n",
    "        self.data = torch.nn.utils.rnn.pad_sequence(\n",
    "            self.data, batch_first=True, padding_value=0\n",
    "        ).float()\n",
    "        # Output classes\n",
    "        self.labels = torch.argmax(self.labels, dim=1)\n",
    "        print(\"Input shape:\", self.data.shape)\n",
    "        print(\"Output shape:\", self.labels.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.lengths[idx]\n",
    "\n",
    "    def one_hot_encoding(self, data, classes):\n",
    "        one_hot_tensors = []\n",
    "        for sequence in data:\n",
    "            one_hot_encoded = []\n",
    "            i = 0\n",
    "            while i < len(sequence):\n",
    "                char = sequence[i]\n",
    "                vector = [0] * len(classes)\n",
    "                if char == \"-\":\n",
    "                    next_char = sequence[i + 1]\n",
    "                    unit = char + next_char\n",
    "                    if unit in classes:\n",
    "                        vector[classes.index(unit)] = 1\n",
    "                        i += 1  # Skip the next character since it forms a unit\n",
    "                elif char in classes:\n",
    "                    vector[classes.index(char)] = 1\n",
    "                one_hot_encoded.append(vector)\n",
    "                i += 1\n",
    "            # Convert the list to a PyTorch tensor\n",
    "            one_hot_tensor = torch.tensor(one_hot_encoded)\n",
    "            one_hot_tensors.append(one_hot_tensor)\n",
    "        return one_hot_tensors\n",
    "\n",
    "    def input_output_prep(self, one_hot_tensors):\n",
    "        input = []\n",
    "        output = []\n",
    "        for one_hot_encoded in one_hot_tensors:\n",
    "            for i in range(len(one_hot_encoded) - 1):\n",
    "                input.append(one_hot_encoded[0 : i + 1])\n",
    "                output.append(one_hot_encoded[i + 1])\n",
    "        lengths = [len(i) for i in input]\n",
    "        output = torch.stack(output)\n",
    "        lengths = torch.tensor(lengths)\n",
    "        return input, output, lengths\n",
    "\n",
    "    def augment_data(self, data):\n",
    "        augmented = []\n",
    "        for i in data:\n",
    "            base = i.numpy()\n",
    "            nognoe = base[1:-1]\n",
    "            for j in range(1,len(nognoe)):\n",
    "                new_rep = torch.from_numpy(np.roll(nognoe,j,axis=0))\n",
    "                augmented.append(torch.cat((i[:1],new_rep,i[-1:]),axis=0))\n",
    "        return data + augmented\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = DATA_DIRECTORY / \"v21D0_m1.npy\"\n",
    "data = np.load(datapath, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
