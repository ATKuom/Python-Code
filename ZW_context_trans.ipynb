{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thermo_validity import *\n",
    "from ZW_model import *\n",
    "from ZW_utils import *\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from ZW_Opt import *\n",
    "from split_functions import one_hot_encoding, bound_creation\n",
    "\n",
    "dataset_id = \"v21D0_m1.npy\"\n",
    "classes = std_classes\n",
    "data_split_ratio = 0.85\n",
    "batch_size = 100\n",
    "max_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "block_size = 23\n",
    "n_embd = 32  # 32\n",
    "n_head = 4  # 4\n",
    "n_layer = 2  # 2\n",
    "dropout = 0.1  # 0.1\n",
    "vocab_size = len(classes)\n",
    "model = GPT(vocab_size, n_embd, n_head, n_layer, block_size, dropout)\n",
    "loss_function = std_loss\n",
    "augmentation = False\n",
    "N1 = 10\n",
    "cycles1 = 11\n",
    "N2 = 3\n",
    "cycles2 = 8\n",
    "cutoff = 143.957\n",
    "\n",
    "\n",
    "\n",
    "def Transformer_training_cycle(mode, N, save_path, dataset, cycles):\n",
    "    if mode == \"M1\":\n",
    "        for i in range(0, cycles):\n",
    "            train_loader, val_loader = T_integer_data_loaders(\n",
    "                dataset, batch_size, data_split_ratio, classes, block_size, augmentation\n",
    "            )\n",
    "            model = GPT(vocab_size, n_embd, n_head, n_layer, block_size, dropout)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            best_model, last_model, t_loss, v_loss = T_integer_training(\n",
    "                model, optimizer, loss_function, train_loader, val_loader, max_epochs\n",
    "            )\n",
    "            plot_name = mode + \"_loss_\" + str(i) + \".png\"\n",
    "            model_name = mode + \"_model_\" + str(i) + \".pt\"\n",
    "            data_name = mode + \"_data_\" + str(i + 1) + \".npy\"\n",
    "            plt.plot(t_loss, label=\"Training Loss\")\n",
    "            plt.plot(v_loss, label=\"Validation Loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{save_path}/{plot_name}\")\n",
    "            plt.clf()\n",
    "            torch.save(best_model, f\"{save_path}/{model_name}\")\n",
    "            model.load_state_dict(best_model)\n",
    "            layout_list = transformer_generation(model, classes, N)\n",
    "            np.save(f\"{save_path}/{mode}generated_{i}.npy\", layout_list)\n",
    "            new_strings = np.array(validity(layout_list), dtype=object)\n",
    "            prev_strings = np.array(dataset, dtype=object)\n",
    "            new_dataset = np.unique(np.concatenate((prev_strings, new_strings), axis=0))\n",
    "            np.save(f\"{save_path}/{data_name}\", new_dataset)\n",
    "            dataset = new_dataset.tolist()\n",
    "            print(\"Dataset Length:\", len(dataset))\n",
    "    else:\n",
    "        for i in range(0, cycles):\n",
    "            train_loader, val_loader = T_integer_data_loaders(\n",
    "                dataset, batch_size, data_split_ratio, classes, block_size, augmentation\n",
    "            )\n",
    "            model = GPT(vocab_size, n_embd, n_head, n_layer, block_size, dropout)\n",
    "            model.load_state_dict(torch.load(f\"{save_path}/M1_model_10.pt\"))\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            best_model, last_model, t_loss, v_loss = T_integer_training(\n",
    "                model, optimizer, loss_function, train_loader, val_loader, max_epochs\n",
    "            )\n",
    "            plot_name = mode + \"_loss_\" + str(i) + \".png\"\n",
    "            model_name = mode + \"_model_\" + str(i) + \".pt\"\n",
    "            data_name = mode + \"_data_\" + str(i + 1) + \".npy\"\n",
    "            plt.plot(t_loss, label=\"Training Loss\")\n",
    "            plt.plot(v_loss, label=\"Validation Loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{save_path}/{plot_name}\")\n",
    "            plt.clf()\n",
    "            torch.save(best_model, f\"{save_path}/{model_name}\")\n",
    "            model.load_state_dict(best_model)\n",
    "            layout_list = transformer_generation(model, classes, N)\n",
    "            np.save(f\"{save_path}/{mode}generated_{i}.npy\", layout_list)\n",
    "            unique_strings = np.unique(np.array(validity(datalist), dtype=object))\n",
    "            p_datalist = dataset\n",
    "            datalist = np.unique(np.concatenate((p_datalist, unique_strings), axis=0))\n",
    "            candidates = datalist[\n",
    "                np.where(np.isin(unique_strings, p_datalist, invert=True))[0]\n",
    "            ]\n",
    "            candidates_results = optimization(\n",
    "                candidates, classes, save_path, \"candidates_\" + str(i)\n",
    "            )\n",
    "            good_layouts = optimization_filter(candidates_results, candidates, cutoff)\n",
    "            dataset = np.unique(np.concatenate((p_datalist, good_layouts), axis=0))\n",
    "            np.save(f\"{save_path}/{data_name}\", dataset)\n",
    "    return model\n",
    "\n",
    "\n",
    "def optimization(data_array, classes, save_path, save_name):\n",
    "    one_hot_tensors = np.array(one_hot_encoding(data_array, classes), dtype=object)\n",
    "    print(one_hot_tensors.shape)\n",
    "    valid_layouts = set()\n",
    "    penalty_layouts = set()\n",
    "    broken_layouts = set()\n",
    "    results = np.zeros(one_hot_tensors.shape[0])\n",
    "    positions = np.zeros(one_hot_tensors.shape[0], dtype=object)\n",
    "    for i in range(one_hot_tensors.shape[0]):\n",
    "        layout = one_hot_tensors[i]\n",
    "        equipment, bounds, x, splitter = bound_creation(layout)\n",
    "        # PSO Parameters\n",
    "        swarmsize_factor = 7\n",
    "        particle_size = swarmsize_factor * len(bounds)\n",
    "        if 5 in equipment:\n",
    "            particle_size += -1 * swarmsize_factor\n",
    "        if 9 in equipment:\n",
    "            particle_size += -2 * swarmsize_factor\n",
    "        iterations = 30\n",
    "        nv = len(bounds)\n",
    "        try:\n",
    "            a = PSO(\n",
    "                objective_function, bounds, particle_size, iterations, nv, equipment\n",
    "            )\n",
    "            if a.result < 1e6:\n",
    "                valid_layouts.add(i)\n",
    "                results[i] = a.result\n",
    "                positions[i] = a.points\n",
    "            else:\n",
    "                penalty_layouts.add(i)\n",
    "        except:\n",
    "            broken_layouts.add(i)\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                \"Valid/Penalty/Broken\",\n",
    "                len(valid_layouts),\n",
    "                len(penalty_layouts),\n",
    "                len(broken_layouts),\n",
    "            )\n",
    "    results_name = \"results_\" + save_name + \".npy\"\n",
    "    positions_name = \"positions_\" + save_name + \".npy\"\n",
    "    np.save(f\"{save_path}\\{results_name}\", results)\n",
    "    np.save(f\"{save_path}\\{positions_name}\", positions)\n",
    "    return results\n",
    "\n",
    "\n",
    "def optimization_filter(results, datalist, cutoff, save_name):\n",
    "    nonzero_results = results[np.where(results > 0)]\n",
    "    good_layouts = []\n",
    "    good_results = []\n",
    "    print(\"Optimization Results:\", len(nonzero_results), len(results))\n",
    "    for i in range(len(results)):\n",
    "        if results[i] < cutoff and results[i] > 0:\n",
    "            good_layouts.append(datalist[i])\n",
    "            good_results.append(results[i])\n",
    "    print(\"Good layouts\", len(good_layouts))\n",
    "    good_layouts = np.array(good_layouts, dtype=object)\n",
    "    np.save(\n",
    "        f\"{save_path}/{save_name}_good_layouts.npy\",\n",
    "        good_layouts,\n",
    "    )\n",
    "    return good_layouts, good_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designs in the dataset v21D0_m1.npy : 1000\n"
     ]
    }
   ],
   "source": [
    "# save_path = make_dir(\n",
    "#     model,\n",
    "#     batch_size,\n",
    "#     learning_rate,\n",
    "# )\n",
    "dataset = dataloading(dataset_id)\n",
    "\n",
    "save_path = \"202407191642_GPT_batch100_lr1e-03\"\n",
    "\n",
    "\n",
    "# dataset = np.load(f\"{save_path}/generated+1_data.npy\", allow_pickle=True).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designs in the dataset: 1000\n",
      "Input shape: torch.Size([1000, 22])\n",
      "Training set size: 850\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     20\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\ZW_model.py:133\u001b[0m, in \u001b[0;36mGPT.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m    130\u001b[0m B, T \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# idx and targets are both (B,T) tensor of integers\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T))  \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb  \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m85830ak\\Python\\Python-Code\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
